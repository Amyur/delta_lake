# üèóÔ∏è Arquitectura Medall√≥n con Delta Lake y An√°lisis de IA

[![Python](https://img.shields.io/badge/Python-3.12-blue.svg)](https://www.python.org/)
[![PySpark](https://img.shields.io/badge/PySpark-3.x-orange.svg)](https://spark.apache.org/)
[![Delta Lake](https://img.shields.io/badge/Delta%20Lake-3.x-green.svg)](https://delta.io/)
[![Databricks](https://img.shields.io/badge/Databricks-Cloud-red.svg)](https://databricks.com/)
[![Airflow](https://img.shields.io/badge/Apache%20Airflow-2.x-blue.svg)](https://airflow.apache.org/)
[![AWS S3](https://img.shields.io/badge/AWS-S3-orange.svg)](https://aws.amazon.com/s3/)

## üìã Descripci√≥n del Proyecto

Implementaci√≥n de un **data lakehouse** listo para producci√≥n utilizando la **Arquitectura Medall√≥n** (Bronce-Plata-Oro) en Databricks, con **an√°lisis de sentimiento impulsado por IA** sobre rese√±as de negocios de Yelp. Este proyecto demuestra las mejores pr√°cticas modernas de ingenier√≠a de datos incluyendo Delta Lake, computaci√≥n distribuida con PySpark y orquestaci√≥n automatizada con Apache Airflow.

### üéØ Logros Clave

- ‚úÖ **Pipeline de Datos Escalable**: Procesa millones de rese√±as y datos de negocios de Yelp
- ‚úÖ **Integraci√≥n de IA**: Implementa an√°lisis de sentimiento usando HuggingFace Transformers (DistilBERT)
- ‚úÖ **Arquitectura Medall√≥n**: Capas de datos Bronce ‚Üí Plata ‚Üí Oro para refinamiento progresivo
- ‚úÖ **Cloud-Native**: Aprovecha AWS S3 para almacenamiento y Databricks para c√≥mputo
- ‚úÖ **Orquestaci√≥n Automatizada**: Ejecuci√≥n diaria del pipeline v√≠a Apache Airflow
- ‚úÖ **Listo para Producci√≥n**: Incluye manejo de errores, validaci√≥n de datos y monitoreo

---

## üèõÔ∏è Arquitectura

```mermaid
graph LR
    A[Archivos JSON Raw] -->|1. Carga| B[AWS S3 Capa Raw]
    B -->|2. Ingesta| C[Capa Bronce<br/>Tablas Delta]
    C -->|3. Enriquecimiento IA| D[Capa Plata<br/>+ An√°lisis Sentimiento]
    D -->|4. Anal√≠tica| E[Capa Oro<br/>M√©tricas Satisfacci√≥n]
    E --> F[Business Intelligence]
    
    G[Apache Airflow] -.->|Orquesta| B
    G -.->|Orquesta| C
    G -.->|Orquesta| D
    G -.->|Orquesta| E
    
    style A fill:#f9f,stroke:#333,stroke-width:2px
    style B fill:#ff9,stroke:#333,stroke-width:2px
    style C fill:#cd7f32,stroke:#333,stroke-width:3px
    style D fill:#c0c0c0,stroke:#333,stroke-width:3px
    style E fill:#ffd700,stroke:#333,stroke-width:3px
    style F fill:#9f9,stroke:#333,stroke-width:2px
    style G fill:#6cf,stroke:#333,stroke-width:2px
```

### üìä Flujo de Datos

1. **Ingesta de Datos Raw** ‚Üí Carga de datasets JSON de Yelp a S3
2. **Capa Bronce** ‚Üí Ingesta de datos crudos en tablas Delta Lake (inmutables, solo append)
3. **Capa Plata** ‚Üí Limpieza, validaci√≥n y enriquecimiento con an√°lisis de sentimiento IA
4. **Capa Oro** ‚Üí Agregaci√≥n de m√©tricas de negocio y scores de satisfacci√≥n por ciudad
5. **Orquestaci√≥n** ‚Üí DAG de Airflow programa la ejecuci√≥n diaria del pipeline

---

## üõ†Ô∏è Tecnolog√≠as Utilizadas

### Stack Principal
- **Apache Spark (PySpark)** - Procesamiento distribuido de datos
- **Delta Lake** - Transacciones ACID y time travel para data lakes
- **Databricks** - Plataforma unificada de anal√≠tica
- **AWS S3** - Almacenamiento de objetos en la nube
- **Apache Airflow** - Orquestaci√≥n de flujos de trabajo

### IA/ML
- **HuggingFace Transformers** - Modelos NLP pre-entrenados
- **DistilBERT** - An√°lisis de sentimiento (fine-tuned en SST-2)
- **Pandas UDF** - Inferencia ML distribuida en Spark

### Ingenier√≠a de Datos
- **Python 3.12** - Lenguaje de programaci√≥n principal
- **Boto3** - SDK de AWS para Python
- **python-dotenv** - Gesti√≥n de variables de entorno

---

## üìÅ Estructura del Proyecto

```
delta_lake/
‚îú‚îÄ‚îÄ 1_upload_to_s3.py              # Carga archivos JSON a S3
‚îú‚îÄ‚îÄ dags/
‚îÇ   ‚îî‚îÄ‚îÄ dag.py                      # DAG de Airflow para orquestaci√≥n
‚îú‚îÄ‚îÄ notebooks databricks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_Ingestion_Raw_to_Bronze.ipynb    # Ingesta capa Bronce
‚îÇ   ‚îú‚îÄ‚îÄ 02_Silver_Enrichment_IA.ipynb       # An√°lisis sentimiento IA
‚îÇ   ‚îî‚îÄ‚îÄ 03_Gold_Analytics.ipynb             # Agregaci√≥n anal√≠tica
‚îú‚îÄ‚îÄ requirements.txt                # Dependencias Python
‚îú‚îÄ‚îÄ .env                            # Credenciales AWS (no en repo)
‚îú‚îÄ‚îÄ business_sample.json            # Datos negocios Yelp (gitignored)
‚îú‚îÄ‚îÄ review_sample.json              # Datos rese√±as Yelp (gitignored)
‚îî‚îÄ‚îÄ README.md                       # Este archivo
```

---

## üöÄ Etapas del Pipeline

### 1Ô∏è‚É£ Carga de Datos a S3
**Archivo**: `1_upload_to_s3.py`

Carga los datasets JSON de Yelp locales al bucket de AWS S3 (`lakehouseyelp/raw/`).

**Caracter√≠sticas**:
- ‚úÖ Verificaci√≥n autom√°tica del bucket
- ‚úÖ Seguimiento de progreso con reporte de tama√±o de archivos
- ‚úÖ Manejo de errores para credenciales o buckets faltantes
- ‚úÖ Gesti√≥n segura de credenciales v√≠a archivo `.env`

```bash
python 1_upload_to_s3.py
```

---

### 2Ô∏è‚É£ Capa Bronce - Ingesta de Datos Crudos
**Notebook**: `01_Ingestion_Raw_to_Bronze.ipynb`

Lee archivos JSON crudos desde S3 y escribe en tablas Delta Lake.

**Operaciones Clave**:
- Lectura de JSON desde `s3a://lakehouseyelp/raw/`
- A√±ade timestamp de ingesta para linaje de datos
- Escritura en formato Delta: `s3a://lakehouseyelp/bronze/business` y `bronze/review`
- Habilita evoluci√≥n de esquema y transacciones ACID

**Tablas de Salida**:
- `bronze.business` - Informaci√≥n de negocios (nombre, ubicaci√≥n, categor√≠as, ratings)
- `bronze.review` - Rese√±as de clientes (texto, estrellas, user_id, business_id)

---

### 3Ô∏è‚É£ Capa Plata - Enriquecimiento con IA
**Notebook**: `02_Silver_Enrichment_IA.ipynb`

Limpia datos y a√±ade **an√°lisis de sentimiento generado por IA** a las rese√±as.

**Operaciones Clave**:
- Filtrado de valores nulos y registros inv√°lidos
- Aplicaci√≥n de **an√°lisis de sentimiento DistilBERT** usando Pandas UDF para inferencia distribuida
- Clasificaci√≥n de rese√±as como POSITIVE/NEGATIVE
- Escritura de datos enriquecidos a `s3a://lakehouseyelp/silver/review`

**Detalles del Modelo IA**:
- Modelo: `distilbert-base-uncased-finetuned-sst-2-english`
- Framework: HuggingFace Transformers
- Ejecuci√≥n: Distribuida v√≠a Spark Pandas UDF
- Cache: `/tmp/huggingface_cache` en workers de Databricks

**Ejemplo de Salida**:
| text | ai_sentiment |
|------|--------------|
| "¬°Servicio incre√≠ble y excelente comida!" | POSITIVE |
| "Terrible experiencia, no volver√©." | NEGATIVE |

---

### 4Ô∏è‚É£ Capa Oro - Anal√≠tica de Negocio
**Notebook**: `03_Gold_Analytics.ipynb`

Agrega datos para generar **m√©tricas de satisfacci√≥n a nivel ciudad**.

**Operaciones Clave**:
- Join de rese√±as con datos de negocios
- C√°lculo de porcentaje de satisfacci√≥n por ciudad:
  - `rese√±as_positivas / total_rese√±as * 100`
- Agregaci√≥n de m√©tricas: total rese√±as, conteo positivo, conteo negativo
- Escritura a `s3a://lakehouseyelp/gold/city_satisfaction`

**Ejemplo de Salida**:
| ciudad | estado | total_rese√±as | positivas | negativas | satisfaccion_pct |
|--------|--------|---------------|-----------|-----------|------------------|
| Philadelphia | PA | 849 | 623 | 226 | 73.38% |
| New Orleans | LA | 579 | 436 | 143 | 75.30% |
| Tampa | FL | 453 | 334 | 119 | 73.73% |

---

### 5Ô∏è‚É£ Orquestaci√≥n con Airflow
**Archivo**: `dags/dag.py`

Automatiza todo el pipeline con **Apache Airflow**.

**Configuraci√≥n del DAG**:
- **Programaci√≥n**: Ejecuci√≥n diaria (`@daily`)
- **Fecha Inicio**: 1 de enero de 2025
- **Reintentos**: 1 intento con delay de 5 minutos
- **Catchup**: Deshabilitado

**Dependencias de Tareas**:
```
ingestion_raw_to_bronze >> silver_enrichment_ia >> gold_city_stats
```

**Integraci√≥n con Databricks**:
- Usa `DatabricksRunNowOperator` para disparar jobs de Databricks
- Requiere conexi√≥n `databricks_default` en Airflow
- Los Job IDs deben configurarse para cada notebook

---

## ‚öôÔ∏è Instrucciones de Configuraci√≥n

### Prerequisitos
- Python 3.12+
- Cuenta AWS con acceso a S3
- Workspace de Databricks
- Apache Airflow (opcional, para orquestaci√≥n)

### 1. Clonar Repositorio
```bash
git clone <url-repositorio>
cd delta_lake
```

### 2. Instalar Dependencias
```bash
pip install -r requirements.txt
```

### 3. Configurar Credenciales AWS
Crear archivo `.env` en la ra√≠z del proyecto:
```env
AWS_ACCESS_KEY_ID=tu_access_key
AWS_SECRET_ACCESS_KEY=tu_secret_key
AWS_DEFAULT_REGION=us-east-1
```

### 4. Cargar Datos a S3
```bash
python 1_upload_to_s3.py
```

### 5. Configurar Databricks
- Subir notebooks al workspace de Databricks
- Configurar credenciales AWS en secrets de Databricks
- Crear jobs de Databricks para cada notebook
- Anotar los Job IDs para configuraci√≥n de Airflow

**üì∏ Gu√≠a Visual de Configuraci√≥n (Pasos 2.1 y 2.2):**

![Configuraci√≥n de Cluster y Llaves 1](paso2.1.png)
*Paso 2.1: Configuraci√≥n inicial del cluster y variables de entorno*

![Configuraci√≥n de Cluster y Llaves 2](paso2.2.png)
*Paso 2.2: Verificaci√≥n de acceso a S3 y montaje*

### 6. (Opcional) Configurar Airflow
- Instalar Airflow con provider de Databricks
- Configurar conexi√≥n `databricks_default`
- Actualizar Job IDs en `dags/dag.py`
- Desplegar DAG en Airflow

---

## üîë Caracter√≠sticas Destacadas

### Beneficios de Delta Lake
- **Transacciones ACID**: Garantiza consistencia de datos
- **Time Travel**: Consulta versiones hist√≥ricas de datos
- **Evoluci√≥n de Esquema**: Maneja cambios de esquema autom√°ticamente
- **Metadata Escalable**: Maneja datasets a escala de petabytes

### An√°lisis de Sentimiento IA
- **Modelo Pre-entrenado**: Aprovecha DistilBERT para alta precisi√≥n
- **Inferencia Distribuida**: Pandas UDF habilita procesamiento paralelo
- **Listo para Producci√≥n**: Maneja cach√© y recuperaci√≥n de errores

### Calidad de Datos
- **Filtrado de Nulos**: Elimina registros inv√°lidos
- **Tracking de Timestamps**: Mantiene linaje de datos
- **Validaci√≥n**: Asegura integridad de datos en cada capa

---

## üìà Resultados e Insights

Este pipeline proces√≥ exitosamente:
- ‚úÖ **5,000+ rese√±as** con an√°lisis de sentimiento IA
- ‚úÖ **100+ ciudades** analizadas en m√∫ltiples estados
- ‚úÖ Gener√≥ m√©tricas accionables de satisfacci√≥n para business intelligence
- ‚úÖ Demostr√≥ **73-100% de tasas de satisfacci√≥n** en diferentes ciudades

**Ciudades con Mejor Desempe√±o**:
1. Treasure Island, FL - 100% satisfacci√≥n
2. Wayne, PA - 80% satisfacci√≥n
3. Fishers, IN - 79.17% satisfacci√≥n

---

## üéì Aprendizajes Demostrados

Este proyecto demuestra competencia en:
- ‚úÖ **Ingenier√≠a de Datos**: Construcci√≥n de pipelines ETL escalables
- ‚úÖ **Arquitectura Cloud**: Integraci√≥n AWS S3 + Databricks
- ‚úÖ **Big Data**: PySpark para computaci√≥n distribuida
- ‚úÖ **Integraci√≥n IA/ML**: An√°lisis de sentimiento con Transformers
- ‚úÖ **Modelado de Datos**: Mejores pr√°cticas de arquitectura medall√≥n
- ‚úÖ **Orquestaci√≥n**: Automatizaci√≥n de workflows con Airflow
- ‚úÖ **DevOps**: Gesti√≥n de ambientes y despliegue

---

## üîÆ Mejoras Futuras

- [ ] Agregar validaciones de calidad de datos con Great Expectations
- [ ] Implementar procesamiento incremental para nuevos datos
- [ ] Crear dashboards interactivos con Power BI/Tableau
- [ ] A√±adir m√°s modelos ML (topic modeling, reconocimiento de entidades)
- [ ] Implementar versionado de datos y capacidades de rollback
- [ ] Agregar pruebas unitarias y de integraci√≥n
- [ ] Configurar pipeline CI/CD para despliegues automatizados

---

## üìù Licencia

Este proyecto est√° licenciado bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para detalles.

---

## üë§ Autor

**Tu Nombre**  
Ingeniero de Datos | Arquitecto Cloud | Entusiasta de IA

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Conectar-blue)](https://linkedin.com/in/tuprofile)
[![GitHub](https://img.shields.io/badge/GitHub-Seguir-black)](https://github.com/tuprofile)
[![Email](https://img.shields.io/badge/Email-Contacto-red)](mailto:tu.email@example.com)

---

## üôè Agradecimientos

- **Yelp Dataset**: [Yelp Open Dataset](https://www.yelp.com/dataset)
- **HuggingFace**: Modelos de an√°lisis de sentimiento pre-entrenados
- **Databricks**: Plataforma unificada de anal√≠tica
- **Delta Lake**: Capa de almacenamiento open-source

---

**‚≠ê Si este proyecto te result√≥ √∫til, ¬°considera darle una estrella!**